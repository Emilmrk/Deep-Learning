import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import os

IMG_SIZE = (48, 48)
BATCH_SIZE = 32
NUM_CLASSES = 7
EPOCHS_FASE1 = 20
EPOCHS_FASE2 = 10
TOTAL_EPOCHS = EPOCHS_FASE1 + EPOCHS_FASE2

data_dir = '../train'
os.makedirs('graficos', exist_ok=True)

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=preprocess_input,
    validation_split=0.2,
    rotation_range=15,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=IMG_SIZE,
    color_mode='rgb',
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_generator = train_datagen.flow_from_directory(
    data_dir,
    target_size=IMG_SIZE,
    color_mode='rgb',
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation=tf.nn.leaky_relu, kernel_regularizer=l2(1e-4))(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
output = Dense(NUM_CLASSES, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),
    metrics=['accuracy']
)

print("\nðŸš€ Entrenando FASE 1 (modelo congelado)...\n")

history1 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS_FASE1,
    callbacks=[
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
    ]
)

print("\nðŸ”§ FASE 2: Fine-tuning (descongelando capas finales)...\n")

for layer in base_model.layers[-4:]:
    layer.trainable = True

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),
    metrics=['accuracy']
)

history2 = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=TOTAL_EPOCHS,
    initial_epoch=EPOCHS_FASE1,
    callbacks=[
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
    ]
)

model.save('fer2013_mobnetv2_finetuned_extra.h5')

history = {
    'accuracy': history1.history['accuracy'] + history2.history['accuracy'],
    'val_accuracy': history1.history['val_accuracy'] + history2.history['val_accuracy'],
    'loss': history1.history['loss'] + history2.history['loss'],
    'val_loss': history1.history['val_loss'] + history2.history['val_loss'],
}

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history['accuracy'], label='Entrenamiento')
plt.plot(history['val_accuracy'], label='ValidaciÃ³n')
plt.title('Accuracy por Ã©poca')
plt.xlabel('Ã‰poca')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history['loss'], label='Entrenamiento')
plt.plot(history['val_loss'], label='ValidaciÃ³n')
plt.title('Loss por Ã©poca')
plt.xlabel('Ã‰poca')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.savefig('graficos/grafico_entrenamiento_mobnetv2_finetune_extra.png')
plt.close()

val_steps = val_generator.samples // BATCH_SIZE + 1
y_pred_probs = model.predict(val_generator, steps=val_steps, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = val_generator.classes[:len(y_pred)]

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 8))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(val_generator.class_indices.keys()))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Matriz de ConfusiÃ³n MobileNetV2 (Fine-Tuned + Extra)")
plt.savefig('graficos/matriz_confusion_mobnetv2_finetune_extra.png')
plt.close()
